{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a33fb01948fb43",
   "metadata": {},
   "source": [
    "# Baseline system of DBO detection model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5777f8ea",
   "metadata": {},
   "source": [
    "The Jupyter notebook ‘dbo_baseline.ipynb’ contains the code for creating the baseline system for fine-grained detection of various types of attacks on the **free democratic basic order (DBO)** (**subtask 2** of the Shared Task on Harmful Content Detection). A gradient boosting algorithm was chosen for classification, using sentence embeddings and a polarity score as features. The notebook includes the training of the system as well as the prediction on the test data and the evaluation. \n",
    "\n",
    "The programme was tested using Python version 3.12.9. Executing the following two lines of code will install all necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae56681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "pandas==2.2.3\n",
    "spacy==3.8.2\n",
    "scikit-learn==1.6.1\n",
    "textblob==0.15.3\n",
    "textblob-de==0.4.3\n",
    "sentence-transformers==4.1.0\n",
    "nltk==3.9.1\n",
    "numpy==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e92a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f3b8e",
   "metadata": {},
   "source": [
    "## 1. Importing training data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802366fb",
   "metadata": {},
   "source": [
    "First, the training data was read in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478fd0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>DBO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Der Riese ist geweckt,mit oder ohne Verräter u...</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gut Ding will Weile haben...  (y)</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sollen sie doch nach Saudi Arabien</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Volle Zustimmung.??</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mal sehen wann wir an der Erderwärmung schuld ...</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description      DBO\n",
       "0  Der Riese ist geweckt,mit oder ohne Verräter u...  nothing\n",
       "1                  Gut Ding will Weile haben...  (y)  nothing\n",
       "2                 Sollen sie doch nach Saudi Arabien  nothing\n",
       "3                                Volle Zustimmung.??  nothing\n",
       "4  Mal sehen wann wir an der Erderwärmung schuld ...  nothing"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "filename = 'dbo_train.csv' # Path needs to be adjusted  \n",
    "# Reading in training data \n",
    "train_dbo = pd.read_csv(filename, sep=';')\n",
    "train_dbo.drop('id', axis=1, inplace=True) \n",
    "train_dbo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b55f9c9",
   "metadata": {},
   "source": [
    "The class distribution of the training data was analysed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e77edb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Frequency  Percentage\n",
      "DBO                              \n",
      "nothing          6277       84.21\n",
      "criticism         804       10.79\n",
      "agitation         313        4.20\n",
      "subversive         60        0.80\n"
     ]
    }
   ],
   "source": [
    "# Absolute number of instances in each class \n",
    "class_counts_dbo = train_dbo[\"DBO\"].value_counts()\n",
    "\n",
    "# Relative number of instances in each class \n",
    "class_percent_dbo = train_dbo['DBO'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Summarise into a dataframe\n",
    "class_table_dbo = pd.DataFrame({\n",
    "    'Frequency': class_counts_dbo,\n",
    "    'Percentage': class_percent_dbo.round(2)\n",
    "})\n",
    "\n",
    "print(class_table_dbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f26adcefbf63cfe",
   "metadata": {},
   "source": [
    "## 2. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b9004",
   "metadata": {},
   "source": [
    "The training data was then pre-processed. First, basic cleaning steps were carried out (removing URLs, hashtags and mentions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dc1b95c7d7c739",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T20:43:24.462626Z",
     "start_time": "2025-03-12T20:43:24.321673Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'\\d+', ' NUM ', text)  # Replace numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87dfa1c",
   "metadata": {},
   "source": [
    "The tweets were then lemmatised and tokenised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4156ae41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_md-3.8.0/de_core_news_md-3.8.0-py3-none-any.whl (44.4 MB)\n",
      "     ---------------------------------------- 0.0/44.4 MB ? eta -:--:--\n",
      "     ------------- ------------------------ 16.3/44.4 MB 113.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- --- 40.1/44.4 MB 111.0 MB/s eta 0:00:01\n",
      "     --------------------------------------- 44.4/44.4 MB 94.1 MB/s eta 0:00:00\n",
      "Installing collected packages: de-core-news-md\n",
      "Successfully installed de-core-news-md-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "# Download the Spacy Pipeline for the German language \n",
    "! python -m spacy download de_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0785d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('de_core_news_md')\n",
    "\n",
    "# Defining the lemmatisation function \n",
    "def text_lemmatize_tokenize(texts):\n",
    "    lemmatized = []\n",
    "    for doc in nlp.pipe(texts, batch_size = 30):\n",
    "        tokens = [token.lemma_.lower() for token in doc if not token.is_punct]\n",
    "        lemmatized.append(' '.join(tokens))\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdf3b1d",
   "metadata": {},
   "source": [
    "The two functions for removing certain tokens and for lemmatisation were applied to the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3f19a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing URLs, hashtags and mentions \n",
    "train_dbo['description'] = train_dbo['description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "301b6257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatisation and tokenisation\n",
    "train_dbo = train_dbo[train_dbo['description'].notnull()] \n",
    "texts = train_dbo['description'].astype(str).tolist()\n",
    "train_dbo['description'] = text_lemmatize_tokenize(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f9850329ee7b8",
   "metadata": {},
   "source": [
    "## 3. Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f34fd",
   "metadata": {},
   "source": [
    "Next, the tweets from the training data were converted into a feature representation. A polarity value and a sentence embedding representation of the tweets were used as features. Polarity was determined using the TextBlob library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c978fadee1c19421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T20:49:19.178887Z",
     "start_time": "2025-03-12T20:43:51.150668Z"
    }
   },
   "outputs": [],
   "source": [
    "from textblob_de import TextBlobDE\n",
    "\n",
    "# Function for determining the polarity of a tweet\n",
    "def add_polarity(df):\n",
    "    def calculate_sentiment_features(text):\n",
    "        blob = TextBlobDE(text)\n",
    "        return blob.sentiment.polarity\n",
    "\n",
    "    df[['polarity']] = df['description'].apply(lambda x: pd.Series(calculate_sentiment_features(x)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ab3e60",
   "metadata": {},
   "source": [
    "Sentence-Bert was used to extract sentence embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48faf606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def add_semantic_features(df):\n",
    "    sentence_model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "    texts = df['description'].astype(str).values.tolist()\n",
    "\n",
    "    embeddings = sentence_model.encode(texts, show_progressbar=True)\n",
    "    embeddings_df = pd.DataFrame(embeddings, columns=[f'embedding_{i}' for i in range(embeddings.shape[1])])\n",
    "\n",
    "    df = pd.concat([df.reset_index(drop=True), embeddings_df.reset_index(drop=True)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b960a7f",
   "metadata": {},
   "source": [
    "The features were extracted from the tweets in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "584c0ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to \\\\na2.hs-\n",
      "[nltk_data]     mittweida.de\\felser\\Wappscfg\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to \\\\na2.hs-\n",
      "[nltk_data]     mittweida.de\\felser\\Wappscfg\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to \\\\na2.hs-\n",
      "[nltk_data]     mittweida.de\\felser\\Wappscfg\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f8f6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of the polarity score\n",
    "train_dbo = add_polarity(train_dbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f5945ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description      DBO  polarity  \\\n",
      "0  der riese sein wecken mit oder ohne verräter u...  nothing       0.0   \n",
      "1                      gut ding wollen weile haben y  nothing       1.0   \n",
      "2                 sollen sie doch nach saudi arabien  nothing       0.0   \n",
      "3                                    voll zustimmung  nothing       0.0   \n",
      "4  mal sehen wann wir an der erderwärmung schuld ...  nothing       0.0   \n",
      "\n",
      "   embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
      "0    -0.028958    -0.005247     0.031000    -0.046794     0.036813   \n",
      "1     0.011647    -0.010070     0.002322    -0.018418     0.014898   \n",
      "2     0.009813     0.015485    -0.003578     0.011890     0.023747   \n",
      "3    -0.015497    -0.039983    -0.031479     0.009015     0.036269   \n",
      "4     0.003369    -0.109731    -0.015453     0.055244    -0.028149   \n",
      "\n",
      "   embedding_5  embedding_6  ...  embedding_502  embedding_503  embedding_504  \\\n",
      "0    -0.011903     0.011446  ...      -0.062236      -0.000374       0.012991   \n",
      "1     0.011931     0.007304  ...      -0.009890      -0.002892       0.014756   \n",
      "2    -0.021021    -0.039350  ...      -0.035632       0.009216       0.024032   \n",
      "3    -0.014111     0.014375  ...      -0.024105      -0.010252      -0.005823   \n",
      "4     0.015246    -0.021724  ...      -0.026101      -0.042091       0.055269   \n",
      "\n",
      "   embedding_505  embedding_506  embedding_507  embedding_508  embedding_509  \\\n",
      "0      -0.010128      -0.009991       0.030476      -0.022970      -0.002800   \n",
      "1      -0.010098       0.004779       0.009467      -0.006320       0.007242   \n",
      "2       0.002836      -0.024767      -0.000846      -0.025462       0.018092   \n",
      "3       0.003110       0.001261      -0.009597       0.026781      -0.024283   \n",
      "4      -0.045107      -0.012701      -0.022918       0.008512      -0.038525   \n",
      "\n",
      "   embedding_510  embedding_511  \n",
      "0      -0.030245      -0.015067  \n",
      "1       0.007760      -0.016734  \n",
      "2      -0.001307       0.012194  \n",
      "3      -0.035154      -0.051886  \n",
      "4       0.040477       0.012438  \n",
      "\n",
      "[5 rows x 515 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extraction of embedding features \n",
    "train_dbo = add_semantic_features(train_dbo)\n",
    "print(train_dbo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990ba6feb265de3",
   "metadata": {},
   "source": [
    "## 4. Encoding labels and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9c72a7",
   "metadata": {},
   "source": [
    "Before the classifier could be trained, further adjustments to the training data were necessary. In particular, the class labels (*subversive*, *agitation*, *criticism*, *nothing*) were mapped to numerical values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e738bf1f7ac258c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T20:56:55.532926Z",
     "start_time": "2025-03-12T20:56:55.425930Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dbo['DBO_encoded']= train_dbo['DBO'].apply(lambda x: ['agitation', 'criticism', 'nothing', 'subversive'].index(x))\n",
    "X_train = train_dbo.drop(columns=['description', 'DBO', 'DBO_encoded'])\n",
    "y_train = train_dbo['DBO_encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7f8c1b",
   "metadata": {},
   "source": [
    "A gradient boosting algorithm was chosen for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924baa094b1d86b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T21:04:39.866491Z",
     "start_time": "2025-03-12T20:56:57.345668Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8270616",
   "metadata": {},
   "source": [
    "## 5. Prediction on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e37c711",
   "metadata": {},
   "source": [
    "Predictions were then made on the test data using the trained gradient boosting model. For this purpose, the test data was preprocessed in the same way as the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af03a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the test data\n",
    "filename = \"dbo_test.csv\" # Path needs to be adjusted \n",
    "test_dbo = pd.read_csv(filename, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "734ccded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing URLs, hashtags and mentions \n",
    "test_dbo['description'] = test_dbo['description'].apply(clean_text)\n",
    "\n",
    "# Lemmatisation and tokenisation \n",
    "test_dbo['description'] = text_lemmatize_tokenize(test_dbo['description'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d22b73",
   "metadata": {},
   "source": [
    "The same features are extracted from the test data as from the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0d9a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of the polarity score\n",
    "test_dbo = add_polarity(test_dbo)\n",
    "\n",
    "# Extraction of embedding features \n",
    "test_dbo = add_semantic_features(test_dbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30e639",
   "metadata": {},
   "source": [
    "The extracted features of the test data are passed to the gradient boosting model for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da719206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict test data set to features \n",
    "X_test = test_dbo.drop(columns=['id', 'description'])\n",
    "# Prediction \n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13430d55",
   "metadata": {},
   "source": [
    "## 6. Evaluation of results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a87da",
   "metadata": {},
   "source": [
    "The predictions based on the test data were compared with the gold standard and some basic evaluation metrics were calculated. The results achieved serve as a guide and baseline for the competition participants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a23570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the gold standard \n",
    "filename = \"dbo_gold.csv\" # Path needs to be adjusted \n",
    "gold_dbo = pd.read_csv(filename, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdfdf36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels \n",
    "gold_dbo['DBO']= gold_dbo['DBO'].apply(lambda x: ['agitation', 'criticism', 'nothing', 'subversive'].index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e19ad40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the IDs from the test data and the gold standard are in the same order. \n",
    "gold_dbo[\"id\"].tolist() == test_dbo[\"id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d13dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the actual label of the test data\n",
    "y_true = gold_dbo['DBO']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280e62d",
   "metadata": {},
   "source": [
    "The macro metric F1 serves as the main evaluation metric used to calculate the ranking on the leaderboard for the competition. In addition, other evaluation metrics such as precision and recall are calculated for the individual classes, as well as the macro and weighted average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f4fa694e2885e12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T21:06:40.168755Z",
     "start_time": "2025-03-12T21:06:39.582981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.01      0.02       134\n",
      "           1       0.59      0.29      0.39       345\n",
      "           2       0.87      0.97      0.92      2690\n",
      "           3       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.85      3194\n",
      "   macro avg       0.38      0.32      0.33      3194\n",
      "weighted avg       0.80      0.85      0.82      3194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "test_report = classification_report(y_true, y_test_pred)\n",
    "print(\"Train Classification Report:\")\n",
    "print(test_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
