---
title: "Baseline systems"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

The **Large Language Model (LLM)** Qwen2.5 with 32 billion parameters was used as the base system for violence detection. The LLM was prompted in a few-shot scenario for binary classification of tweets. Ollama was used for local running of the LLM.

# 1. Importing the test data

```{r}
# Loading all necessary libraries 
library(jsonlite)
library(httr)
library(readr)
library(stringr)
library(rebus)
```

```{r}
# Importing the test data  
test_data_vio <- read_csv2("../../data/data_shared_task/competition/vio/vio_test_additional.csv") # Path needs to be adjusted 
```

# 2. Prompt Engineering

The LLM was assigned the role of a filter system via a system prompt, whose task is to monitor German tweets. In addition, the LLM was given the definition of violence-related statements, which was based on the definition provided to the annotators during the annotation process.

```{r}
# System prompt for vio
system_prompt_vio <- "FROM qwen2.5:32b SYSTEM \"\"\"Instruction:\n You are a filter system in a social network that specialises in monitoring German tweets. Your task is to detect worrying positive attitudes towards violence.\nConsider the following definitions: A tweet contains a worrying violence-related statement if it trivialises, advocates, glorifies, incites violence or announces the use of violence. Violence is understood to mean active, aggressive behaviour, i.e. the infliction of physical, sexual or psychological violence. If you predict a violence-related statement, your response is \"true\". If you predict a no-violence-related statement, you respond with \"false\". You only respond with one single word and not more! \"\"\" "
```

The user prompt explained the classification task to the LLM. The examples required for in-context learning corresponded to those presented to the annotators and can also be found on the [competition website](https://www.codabench.org/competitions/4963/).

```{r}
# User Prompt for Violence classification
user_prompt_vio <- 'Determine whether the input tweet contains a worrying violence-related statement. Respond with a single word. Do not provide explanations or notes. Your only possible responses, regarding if the provided text contains a worrying violence-related statement are true and false. \nExamples of classification are:\n@UserXY Wenn ich diesen Typ schon sehe, kÃ¶nnte ich ihn an die Wand stellen ðŸ¤¬ response: \"true\"\nKnallt das ganze linksgrÃ¼n Dumme Antifa Gesindel einfach ab! #LinksfaschistenStoppen  response: \"true\"\nMan stelle sich vor, eine Gruppe on 40 jungen MÃ„NNERN [â€¦], teilweise BEWAFFNET [â€¦], versucht ILLEGAL eine Grenze zu Ã¼bertreten, [â€¦] und dann wundert man sich, wenn das Feuer gerechtfertigterweise erÃ¶ffnet wird.  response: \"true\"\n@UserXY endlich hat jemand den Mut ergriffen und dem Mistkerl die Fresse poliert. Der hat alles schlimme der Welt und mehr verdient dieser erbÃ¤rmliche Perverse und geistig Behinderte #VolksverrÃ¤ter response: \"true\"\n@UserXY DU BIST TEIL dieser ganz GEZIELT INSZENIERTEN LÃœGE Ã¼ber Lynchjustiz und Aufruf zu Mord und versuchst alle durch FREI ERFUNDENE HORRORGeschichten in PANIK zu VERSETZEN! #LÃ¼genpresse  response: \"true\"\n\"[â€¦] Der 27- jÃ¤hrige Syrer wird verdÃ¤chtigt, zwischen 2011 und 2014 als Mitglied von Jabhat al- Nusra bzw. Kataib Al Faroug im syrischen BÃ¼rgerkrieg gegen AnhÃ¤nger bzw. Truppen des Assad- Regimes gekÃ¤mpft und auf diese geschossen zu haben\", sagte Peter Oehm, der Leiter des Landesamtes fÃ¼r Verfassungsschutz.  response: \"false\" Input: '
```

# 3. Defining the classification function

The following function is used to classify a single tweet by the LLM. It checks whether the LLM has actually provided a valid answer (`true` or `false`). If not, it is prompted again to classify the tweet. 

```{r}
classify_llm <- function(index, system_prompt, user_prompt, texts){
  error_occurred <- TRUE
  n_trials <- 0
  while (error_occurred && n_trials < 10) {
    # Increase the number of attempts 
    n_trials <- n_trials + 1
    tryCatch({
      request_body <- list(
      model = "qwen2.5:32b",
      prompt = str_escape(paste0(user_prompt, texts[index])),
      format = "json",
      seed = "123",
      stream = FALSE,
      modelfile = str_escape(system_prompt))
      request_body_json <- toJSON(request_body, auto_unbox = TRUE)
      result <- POST("141.55.226.254:11434/api/generate",
                     body = request_body_json,
                     add_headers(.headers = c("Content-Type"="application/json")))
      Output <- httr::content(result)
      Output_response <- fromJSON(Output$response)
      # Only permissible answers for the binary classification 
      possible_responses <- c("true", "false")
      # extract the desired answer from the possibly messy output
      result <- unlist(str_extract_all(Output_response, pattern = or1(possible_responses)))
      # Convert the result to lowercase 
      result <- tolower(result)
      # Return result if a correct answer was provided 
      if(result %in% possible_responses){
        error_occurred <- FALSE 
        cat("The classification of the tweet with the id ", index, " was successful. The answer was: ", result, "\n")
      } else{
          cat("Result does not match with the expected class labels. Current result:", result, "Try again for the ",n_trials, "time.\n")
      }
  }, error = function(e) {
      cat("The following error occurred:", e$message, "in tweet with id",  index, ". Try again for the ",n_trials,"time. \n")
  })
  }
  
  if (error_occurred) {
    result <- paste("Finally failed in id:", index)
  }
  
  return(result)
}
```

# 4. Classification of test data 

All tweets were classified one after the other by the LLM. 

```{r}
library(pbapply)
texts_vio <- test_data_vio$description
pred_qwen_vio <- pbsapply(seq_along(texts_vio), classify_llm, system_prompt_vio, user_prompt_vio, texts_vio)
```

```{r}
# Extract all unique answers
unique(pred_qwen_vio)

library(dplyr)
# Extract subset of unclassified tweets 
misclassified_tweets <- test_data_vio[c(1153, 1573, 2704), ]
```

The LLM was asked again to classify the tweets that it had not labelled. 

```{r}
pred_qwen_vio_unknown <- pbsapply(seq_along(misclassified_tweets$description), classify_llm, system_prompt_vio, user_prompt_vio, misclassified_tweets$description)
pred_qwen_vio_unknown
```

Since Qwen was unable to classify the three tweets, they were classified as `false`. 

```{r}
# Convert labels in factors
pred_qwen_vio[c(1153, 1573, 2704)] <- c("false", "false", "false")
```

The IDs and predicted class labels for the corresponding tweets were then summarised in a table. 

```{r}
pred_qwen_vio_df <- tibble(id = test_data_vio$id, pred = pred_qwen_vio)
```

# 5. Evaluation 

```{r}
# Importing the gold standard for violence detection 
gold_vio <- read_csv2("../../data/data_shared_task/competition/vio/vio_gold_additional.csv") # Path needs to be adjusted 
```
The ground truth was added as a column to the LLM predictions. 

```{r}
pred_qwen_vio_df$ref <- gold_vio$VIO 
```

The ground truth labels were converted to the Boolean data type. Both the ground truth and the predictions were then converted to factors. 

```{r}
# Convert Boolean (TRUE/ FALSE) values in the gold standard to strings (â€˜trueâ€™/ â€˜falseâ€™) 
pred_qwen_vio_df$ref <- ifelse(pred_qwen_vio_df$ref == TRUE, "true", "false")

# Convert labels in factors
pred_qwen_vio_df$pred <- factor(pred_qwen_vio_df$pred, c("true", "false"))
pred_qwen_vio_df$ref <- factor(pred_qwen_vio_df$ref, c("true", "false"))
```

Subsequently, evaluation measures such as precision, recall and F1 measure, as well as the macro and weighted average of these measures across the two classes, were calculated. 

```{r}
library(crfsuite)
eval_qwen_vio <- crf_evaluation(pred = pred_qwen_vio_df$pred, obs = pred_qwen_vio_df$ref, labels = c("true", "false"))
eval_qwen_vio
```


